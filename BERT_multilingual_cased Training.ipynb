{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b42aac-160b-4dd9-8062-1249b59fffa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:14:03.009292Z",
     "iopub.status.busy": "2024-07-17T12:14:03.008642Z",
     "iopub.status.idle": "2024-07-17T12:14:13.389777Z",
     "shell.execute_reply": "2024-07-17T12:14:13.387876Z",
     "shell.execute_reply.started": "2024-07-17T12:14:03.009239Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (1.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Using cached huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2024.5.15-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "Successfully installed huggingface-hub-0.23.5 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.42.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers pandas torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab72df5-881a-4d38-bd90-7d6681fa19bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:14:20.720275Z",
     "iopub.status.busy": "2024-07-17T12:14:20.719690Z",
     "iopub.status.idle": "2024-07-17T12:14:21.455007Z",
     "shell.execute_reply": "2024-07-17T12:14:21.453497Z",
     "shell.execute_reply.started": "2024-07-17T12:14:20.720219Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>مصروف فلپس ایک کارکردگی، مزاحیہ اور ڈرامائی دو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ایک comely آہستہ ہپپی (Kay کے لینز) اور ان کے ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>الزبتھ وارڈ Gracen، شاید صرف بل کلنٹن کی \"Bimb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ایک مقبول کھیل کے طور پر، سرفنگ بہت سے لوگوں ک...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ایڈورڈ Dmytryk کی \"فائرنگ\" ایک نایاب فلم 1940s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             Tweets\n",
       "0      1  مصروف فلپس ایک کارکردگی، مزاحیہ اور ڈرامائی دو...\n",
       "1      0  ایک comely آہستہ ہپپی (Kay کے لینز) اور ان کے ...\n",
       "2      0  الزبتھ وارڈ Gracen، شاید صرف بل کلنٹن کی \"Bimb...\n",
       "3      1  ایک مقبول کھیل کے طور پر، سرفنگ بہت سے لوگوں ک...\n",
       "4      1  ایڈورڈ Dmytryk کی \"فائرنگ\" ایک نایاب فلم 1940s..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0224648b-48eb-4928-b518-e0a9c95042ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:14:25.340924Z",
     "iopub.status.busy": "2024-07-17T12:14:25.340307Z",
     "iopub.status.idle": "2024-07-17T12:14:25.349751Z",
     "shell.execute_reply": "2024-07-17T12:14:25.347944Z",
     "shell.execute_reply.started": "2024-07-17T12:14:25.340877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reset index to avoid KeyError issues\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3822aa-9863-40a1-9266-8ab765a50abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:14:41.089543Z",
     "iopub.status.busy": "2024-07-17T12:14:41.088998Z",
     "iopub.status.idle": "2024-07-17T12:14:43.317306Z",
     "shell.execute_reply": "2024-07-17T12:14:43.315893Z",
     "shell.execute_reply.started": "2024-07-17T12:14:41.089498Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['Tweets'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset index to avoid KeyError issues\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed1d572-ed48-499c-a1b1-5e0f05d31e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T09:53:59.857512Z",
     "iopub.status.busy": "2024-07-17T09:53:59.856551Z",
     "iopub.status.idle": "2024-07-17T09:54:02.922950Z",
     "shell.execute_reply": "2024-07-17T09:54:02.921741Z",
     "shell.execute_reply.started": "2024-07-17T09:53:59.857460Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m'\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/modeling_utils.py:2796\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2792\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2795\u001b[0m         )\n\u001b[0;32m-> 2796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36596ddf-94a4-42bf-b5e3-6a81d0f7e3a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:05:24.158575Z",
     "iopub.status.busy": "2024-07-01T09:05:24.157618Z",
     "iopub.status.idle": "2024-07-01T09:23:47.954820Z",
     "shell.execute_reply": "2024-07-01T09:23:47.953936Z",
     "shell.execute_reply.started": "2024-07-01T09:05:24.158526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train loss 0.6969861725034813 accuracy 0.5097815454841865\n",
      "Val   loss 0.6916682490458091 accuracy 0.5143415906127771\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train loss 0.6953069319327673 accuracy 0.5060319530485816\n",
      "Val   loss 0.7044368758797646 accuracy 0.5143415906127771\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train loss 0.6952424802196523 accuracy 0.5026084121291164\n",
      "Val   loss 0.6979990800221761 accuracy 0.48565840938722293\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train loss 0.6869892154354602 accuracy 0.5498858819693512\n",
      "Val   loss 0.6748971970131 accuracy 0.5834419817470665\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train loss 0.6505744164654365 accuracy 0.6170524942940985\n",
      "Val   loss 0.6478095259517431 accuracy 0.6264667535853976\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train loss 0.6045348878639439 accuracy 0.6776980762960547\n",
      "Val   loss 0.6069822867090503 accuracy 0.6773142112125162\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train loss 0.5723914237072071 accuracy 0.704271274861428\n",
      "Val   loss 0.6016637564947208 accuracy 0.6773142112125162\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train loss 0.5424868074478582 accuracy 0.7331268340397783\n",
      "Val   loss 0.6058687226225933 accuracy 0.6753585397653195\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train loss 0.5129996423299114 accuracy 0.7536680795565699\n",
      "Val   loss 0.6115565543683866 accuracy 0.7040417209908735\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train loss 0.4873963533124576 accuracy 0.768829475057059\n",
      "Val   loss 0.6041370049739877 accuracy 0.7046936114732725\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train loss 0.45407698264655966 accuracy 0.7921421584610369\n",
      "Val   loss 0.6089571729923288 accuracy 0.711864406779661\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train loss 0.4226322503721652 accuracy 0.8154548418650147\n",
      "Val   loss 0.6079292671444515 accuracy 0.7092568448500651\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train loss 0.39396424607063335 accuracy 0.8270296706879687\n",
      "Val   loss 0.6463201182583967 accuracy 0.7086049543676662\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train loss 0.3780804989898267 accuracy 0.8387675252689925\n",
      "Val   loss 0.6439577294513583 accuracy 0.7105606258148631\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train loss 0.35926375198566046 accuracy 0.8513205086403651\n",
      "Val   loss 0.6529872822575271 accuracy 0.7105606258148631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, correct_bias=False)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff4a51d-a81f-46cd-9878-9fa8d673b028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:25:58.892718Z",
     "iopub.status.busy": "2024-07-01T09:25:58.892135Z",
     "iopub.status.idle": "2024-07-01T09:26:06.652345Z",
     "shell.execute_reply": "2024-07-01T09:26:06.651043Z",
     "shell.execute_reply.started": "2024-07-01T09:25:58.892662Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('path_to_save_tokenizer/tokenizer_config.json',\n",
       " 'path_to_save_tokenizer/special_tokens_map.json',\n",
       " 'path_to_save_tokenizer/vocab.txt',\n",
       " 'path_to_save_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('BERT-CASED')\n",
    "tokenizer.save_pretrained('BERT-CASED-tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1d647c7-8c5e-4fba-a7bd-c823d96cc1f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:28:54.619953Z",
     "iopub.status.busy": "2024-07-01T09:28:54.619510Z",
     "iopub.status.idle": "2024-07-01T09:28:55.186659Z",
     "shell.execute_reply": "2024-07-01T09:28:55.185882Z",
     "shell.execute_reply.started": "2024-07-01T09:28:54.619927Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch  Train Loss  Val Loss  Train Accuracy  Val Accuracy\n",
      "0       1    0.696986  0.691668        0.509782      0.514342\n",
      "1       2    0.695307  0.704437        0.506032      0.514342\n",
      "2       3    0.695242  0.697999        0.502608      0.485658\n",
      "3       4    0.686989  0.674897        0.549886      0.583442\n",
      "4       5    0.650574  0.647810        0.617052      0.626467\n",
      "5       6    0.604535  0.606982        0.677698      0.677314\n",
      "6       7    0.572391  0.601664        0.704271      0.677314\n",
      "7       8    0.542487  0.605869        0.733127      0.675359\n",
      "8       9    0.513000  0.611557        0.753668      0.704042\n",
      "9      10    0.487396  0.604137        0.768829      0.704694\n",
      "10     11    0.454077  0.608957        0.792142      0.711864\n",
      "11     12    0.422632  0.607929        0.815455      0.709257\n",
      "12     13    0.393964  0.646320        0.827030      0.708605\n",
      "13     14    0.378080  0.643958        0.838768      0.710561\n",
      "14     15    0.359264  0.652987        0.851321      0.710561\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    \"Epoch\": list(range(1, 16)),\n",
    "    \"Train Loss\": [\n",
    "        0.6969861725034813, 0.6953069319327673, 0.6952424802196523, 0.6869892154354602, \n",
    "        0.6505744164654365, 0.6045348878639439, 0.5723914237072071, 0.5424868074478582, \n",
    "        0.5129996423299114, 0.4873963533124576, 0.45407698264655966, 0.4226322503721652, \n",
    "        0.39396424607063335, 0.3780804989898267, 0.35926375198566046\n",
    "    ],\n",
    "    \"Val Loss\": [\n",
    "        0.6916682490458091, 0.7044368758797646, 0.6979990800221761, 0.6748971970131, \n",
    "        0.6478095259517431, 0.6069822867090503, 0.6016637564947208, 0.6058687226225933, \n",
    "        0.6115565543683866, 0.6041370049739877, 0.6089571729923288, 0.6079292671444515, \n",
    "        0.6463201182583967, 0.6439577294513583, 0.6529872822575271\n",
    "    ],\n",
    "    \"Train Accuracy\": [\n",
    "        0.5097815454841865, 0.5060319530485816, 0.5026084121291164, 0.5498858819693512, \n",
    "        0.6170524942940985, 0.6776980762960547, 0.704271274861428, 0.7331268340397783, \n",
    "        0.7536680795565699, 0.768829475057059, 0.7921421584610369, 0.8154548418650147, \n",
    "        0.8270296706879687, 0.8387675252689925, 0.8513205086403651\n",
    "    ],\n",
    "    \"Val Accuracy\": [\n",
    "        0.5143415906127771, 0.5143415906127771, 0.48565840938722293, 0.5834419817470665, \n",
    "        0.6264667535853976, 0.6773142112125162, 0.6773142112125162, 0.6753585397653195, \n",
    "        0.7040417209908735, 0.7046936114732725, 0.711864406779661, 0.7092568448500651, \n",
    "        0.7086049543676662, 0.7105606258148631, 0.7105606258148631\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df[\"Epoch\"], df[\"Train Loss\"], label=\"Train Loss\", marker='o')\n",
    "plt.plot(df[\"Epoch\"], df[\"Val Loss\"], label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train and Validation Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Annotating min and max points for train loss\n",
    "plt.annotate(f'Min Train Loss: {df[\"Train Loss\"].min():.4f}', \n",
    "             xy=(df[\"Epoch\"][df[\"Train Loss\"].idxmin()], df[\"Train Loss\"].min()), \n",
    "             xytext=(df[\"Epoch\"][df[\"Train Loss\"].idxmin()] + 1, df[\"Train Loss\"].min() + 0.05),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.annotate(f'Max Train Loss: {df[\"Train Loss\"].max():.4f}', \n",
    "             xy=(df[\"Epoch\"][df[\"Train Loss\"].idxmax()], df[\"Train Loss\"].max()), \n",
    "             xytext=(df[\"Epoch\"][df[\"Train Loss\"].idxmax()] + 1, df[\"Train Loss\"].max() - 0.05),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "# Annotating min and max points for val loss\n",
    "plt.annotate(f'Min Val Loss: {df[\"Val Loss\"].min():.4f}', \n",
    "             xy=(df[\"Epoch\"][df[\"Val Loss\"].idxmin()], df[\"Val Loss\"].min()), \n",
    "             xytext=(df[\"Epoch\"][df[\"Val Loss\"].idxmin()] + 1, df[\"Val Loss\"].min() + 0.05),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "plt.annotate(f'Max Val Loss: {df[\"Val Loss\"].max():.4f}', \n",
    "             xy=(df[\"Epoch\"][df[\"Val Loss\"].idxmax()], df[\"Val Loss\"].max()), \n",
    "             xytext=(df[\"Epoch\"][df[\"Val Loss\"].idxmax()] + 1, df[\"Val Loss\"].max() - 0.05),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f03b7be1-2540-4cba-982f-45e3b72052d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:31:31.856750Z",
     "iopub.status.busy": "2024-07-01T09:31:31.855537Z",
     "iopub.status.idle": "2024-07-01T09:31:32.140086Z",
     "shell.execute_reply": "2024-07-01T09:31:32.139465Z",
     "shell.execute_reply.started": "2024-07-01T09:31:31.856686Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch  Train Loss  Val Loss  Train Accuracy  Val Accuracy\n",
      "0       1    0.696986  0.691668        0.509782      0.514342\n",
      "1       2    0.695307  0.704437        0.506032      0.514342\n",
      "2       3    0.695242  0.697999        0.502608      0.485658\n",
      "3       4    0.686989  0.674897        0.549886      0.583442\n",
      "4       5    0.650574  0.647810        0.617052      0.626467\n",
      "5       6    0.604535  0.606982        0.677698      0.677314\n",
      "6       7    0.572391  0.601664        0.704271      0.677314\n",
      "7       8    0.542487  0.605869        0.733127      0.675359\n",
      "8       9    0.513000  0.611557        0.753668      0.704042\n",
      "9      10    0.487396  0.604137        0.768829      0.704694\n",
      "10     11    0.454077  0.608957        0.792142      0.711864\n",
      "11     12    0.422632  0.607929        0.815455      0.709257\n",
      "12     13    0.393964  0.646320        0.827030      0.708605\n",
      "13     14    0.378080  0.643958        0.838768      0.710561\n",
      "14     15    0.359264  0.652987        0.851321      0.710561\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting Train and Validation Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df[\"Epoch\"], df[\"Train Accuracy\"], label=\"Train Accuracy\", marker='o')\n",
    "plt.plot(df[\"Epoch\"], df[\"Val Accuracy\"], label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train and Validation Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Annotating min and max points for train accuracy\n",
    "plt.annotate(f'Min Train Accuracy: {df[\"Train Accuracy\"].min():.4f}', \n",
    "             xy=(df[\"Epoch\"][df[\"Train Accuracy\"].idxmin()], df[\"Train Accuracy\"].min()), \n",
    "             xytext=(df[\"Epoch\"][df[\"Train Accuracy\"].idxmin()] + 1, df[\"Train Accuracy\"].min() + 0.02),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.annotate(f'Max Train Accuracy: {df[\"Train Accuracy\"].max():.4f}', \n",
    "             xy=(df[\"Epoch\"][df[\"Train Accuracy\"].idxmax()], df[\"Train Accuracy\"].max()), \n",
    "             xytext=(df[\"Epoch\"][df[\"Train Accuracy\"].idxmax()] + 1, df[\"Train Accuracy\"].max() - 0.02),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "# Annotating min and max points for val accuracy\n",
    "plt.annotate(f'Min Val Accuracy: {df[\"Val Accuracy\"].min():.4f}', \n",
    "             xy=(df[\"Epoch\"][df[\"Val Accuracy\"].idxmin()], df[\"Val Accuracy\"].min()), \n",
    "             xytext=(df[\"Epoch\"][df[\"Val Accuracy\"].idxmin()] + 1, df[\"Val Accuracy\"].min() + 0.02),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "plt.annotate(f'Max Val Accuracy: {df[\"Val Accuracy\"].max():.4f}', \n",
    "             xy=(df[\"Epoch\"][df[\"Val Accuracy\"].idxmax()], df[\"Val Accuracy\"].max()), \n",
    "             xytext=(df[\"Epoch\"][df[\"Val Accuracy\"].idxmax()] + 1, df[\"Val Accuracy\"].max() - 0.02),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "088c9964-b122-4db6-9303-206d4593ccb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:45:41.069336Z",
     "iopub.status.busy": "2024-07-01T09:45:41.068963Z",
     "iopub.status.idle": "2024-07-01T09:45:44.323472Z",
     "shell.execute_reply": "2024-07-01T09:45:44.322172Z",
     "shell.execute_reply.started": "2024-07-01T09:45:41.069313Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.9/site-packages (0.4.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f07ae28c-1b16-45f0-a86f-0121f8491dc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T09:54:33.543432Z",
     "iopub.status.busy": "2024-07-01T09:54:33.542119Z",
     "iopub.status.idle": "2024-07-01T09:54:40.760004Z",
     "shell.execute_reply": "2024-07-01T09:54:40.759006Z",
     "shell.execute_reply.started": "2024-07-01T09:54:33.543354Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.5392156832127107 accuracy 0.7688966116420504\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Load your saved model and tokenizer\n",
    "model_path = 'path_to_save_model'\n",
    "tokenizer_path = 'path_to_save_tokenizer'\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, use_safetensors=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index to avoid KeyError issues\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Evaluate on test data\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64055779-71e0-4377-8891-c7c978f38be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T10:14:38.997460Z",
     "iopub.status.busy": "2024-07-01T10:14:38.996431Z",
     "iopub.status.idle": "2024-07-01T10:14:39.005394Z",
     "shell.execute_reply": "2024-07-01T10:14:39.004230Z",
     "shell.execute_reply.started": "2024-07-01T10:14:38.997390Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 1151\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the test dataset\n",
    "print(f'Test dataset size: {len(test_texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0571515-6137-46df-a381-ba7154ad2d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:52:42.640890Z",
     "iopub.status.busy": "2024-07-15T06:52:42.640069Z",
     "iopub.status.idle": "2024-07-15T07:03:46.857613Z",
     "shell.execute_reply": "2024-07-15T07:03:46.856183Z",
     "shell.execute_reply.started": "2024-07-15T06:52:42.640840Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.6879640876182488 accuracy 0.5340040991242779\n",
      "Val   loss 0.6588711332943704 accuracy 0.5956521739130435\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.6366498676971311 accuracy 0.6292155766722564\n",
      "Val   loss 0.5802511105106937 accuracy 0.7017391304347826\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.521644904810403 accuracy 0.7374697223774921\n",
      "Val   loss 0.5760632728536924 accuracy 0.7130434782608696\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.4032689396158925 accuracy 0.8242966275386622\n",
      "Val   loss 0.646524264373713 accuracy 0.6991304347826087\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.2582833897377852 accuracy 0.8969629215576672\n",
      "Val   loss 0.7024351824074984 accuracy 0.7234782608695652\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.1384355836697588 accuracy 0.9487609465250605\n",
      "Val   loss 0.7434955512483915 accuracy 0.7078260869565217\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.08763248305712339 accuracy 0.970933482392398\n",
      "Val   loss 1.0527273139192 accuracy 0.72\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.04369264311459292 accuracy 0.9878889509968325\n",
      "Val   loss 1.3331244140863419 accuracy 0.711304347826087\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.03179475531076258 accuracy 0.9912427799515557\n",
      "Val   loss 1.2284277023540602 accuracy 0.7234782608695652\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.024643569196909777 accuracy 0.9936649897521893\n",
      "Val   loss 1.2772391601983044 accuracy 0.7217391304347827\n",
      "\n",
      "Test loss 1.2401729398924444 accuracy 0.737619461337967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('path_to_save_tokenizer/tokenizer_config.json',\n",
       " 'path_to_save_tokenizer/special_tokens_map.json',\n",
       " 'path_to_save_tokenizer/vocab.txt',\n",
       " 'path_to_save_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_STEPS = 200\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "# Evaluate on test data\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained('path_to_save_model')\n",
    "tokenizer.save_pretrained('path_to_save_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88b7d53-2dc0-41ac-8fa2-7b83caceaecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:20:06.109825Z",
     "iopub.status.busy": "2024-07-15T07:20:06.109259Z",
     "iopub.status.idle": "2024-07-15T07:26:07.698484Z",
     "shell.execute_reply": "2024-07-15T07:26:07.697448Z",
     "shell.execute_reply.started": "2024-07-15T07:20:06.109779Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.693116528292497 accuracy 0.5217067262902925\n",
      "Val   loss 0.6449173837900162 accuracy 0.6408695652173914\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.626800272436369 accuracy 0.6536239985094093\n",
      "Val   loss 0.5802708835237556 accuracy 0.7078260869565217\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.5297564921811933 accuracy 0.7361654555617664\n",
      "Val   loss 0.5644036817053953 accuracy 0.7078260869565217\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.42535959587742883 accuracy 0.8030557108254146\n",
      "Val   loss 0.5991926621645689 accuracy 0.7260869565217392\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.31798135963756413 accuracy 0.8578349170858953\n",
      "Val   loss 0.680660190888577 accuracy 0.7382608695652174\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.5409261182778411 accuracy 0.73501303214596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('BERT_tokenzier/tokenizer_config.json',\n",
       " 'BERT_tokenzier/special_tokens_map.json',\n",
       " 'BERT_tokenzier/vocab.txt',\n",
       " 'BERT_tokenzier/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_STEPS = 200\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.3\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with dropout\n",
    "class CustomBERTModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(outputs.logits)\n",
    "        return pooled_output\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('BERT_tokenzier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b81818e-de04-439a-80e4-f4628ddc0601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:28:24.589158Z",
     "iopub.status.busy": "2024-07-15T07:28:24.588507Z",
     "iopub.status.idle": "2024-07-15T07:33:13.340041Z",
     "shell.execute_reply": "2024-07-15T07:33:13.339156Z",
     "shell.execute_reply.started": "2024-07-15T07:28:24.589104Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.6971865860479218 accuracy 0.5030743432084963\n",
      "Val   loss 0.6976194373435445 accuracy 0.49130434782608695\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.694127527376016 accuracy 0.5086640581330352\n",
      "Val   loss 0.6936951221691238 accuracy 0.49130434782608695\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.6943611307513147 accuracy 0.5019564002235886\n",
      "Val   loss 0.6965796127915382 accuracy 0.49130434782608695\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.6934305612175238 accuracy 0.5176076020122974\n",
      "Val   loss 0.6945306973324882 accuracy 0.5086956521739131\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.6918024412459798 accuracy 0.524761077324066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('BCE_loss_tokenizer/tokenizer_config.json',\n",
       " 'BCE_loss_tokenizer/special_tokens_map.json',\n",
       " 'BCE_loss_tokenizer/vocab.txt',\n",
       " 'BCE_loss_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)  # Change to float for BCEWithLogitsLoss\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_STEPS = 200\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.3\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with dropout\n",
    "class CustomBERTModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=1)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.dropout(outputs.logits)\n",
    "        return logits\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "# Change the loss function to BCEWithLogitsLoss\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits.view(-1), labels)\n",
    "\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        correct_predictions += torch.sum(preds.view(-1) == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits.view(-1), labels)\n",
    "\n",
    "            preds = torch.round(torch.sigmoid(logits))\n",
    "            correct_predictions += torch.sum(preds.view(-1) == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('BCE_loss_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "979a2ac0-f8cb-49c9-bdcf-b1171d25772f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:35:02.174663Z",
     "iopub.status.busy": "2024-07-15T07:35:02.174030Z",
     "iopub.status.idle": "2024-07-15T07:43:20.884222Z",
     "shell.execute_reply": "2024-07-15T07:43:20.883299Z",
     "shell.execute_reply.started": "2024-07-15T07:35:02.174611Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.6911341237525145 accuracy 0.5306502701695547\n",
      "Val   loss 0.6875849771830771 accuracy 0.5208695652173914\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.6437058470078877 accuracy 0.6260480715483511\n",
      "Val   loss 0.64935831228892 accuracy 0.5930434782608696\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.5608976277567091 accuracy 0.7106390907397055\n",
      "Val   loss 0.5786014820138613 accuracy 0.7069565217391305\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.4691924264077984 accuracy 0.7751071362027203\n",
      "Val   loss 0.551488718845778 accuracy 0.74\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.3598411515621202 accuracy 0.8343581144028321\n",
      "Val   loss 0.6279245013785031 accuracy 0.72\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.26045550502437564 accuracy 0.8855971678777715\n",
      "Val   loss 0.7555507487720914 accuracy 0.7382608695652174\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.1870574724383741 accuracy 0.9200670765790945\n",
      "Val   loss 0.9888974239842759 accuracy 0.7391304347826088\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.5309793789767556 accuracy 0.7454387489139878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('BERT_tokenizer/tokenizer_config.json',\n",
       " 'BERT_tokenizer/special_tokens_map.json',\n",
       " 'BERT_tokenizer/vocab.txt',\n",
       " 'BERT_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_STEPS = 200\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.3\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with dropout\n",
    "class CustomBERTModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(outputs.logits)\n",
    "        return pooled_output\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Increased patience\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('BERT_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a69c8f21-3984-4411-9502-6af9d1b593e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:52:27.710215Z",
     "iopub.status.busy": "2024-07-15T07:52:27.709696Z",
     "iopub.status.idle": "2024-07-15T07:59:39.581724Z",
     "shell.execute_reply": "2024-07-15T07:59:39.580524Z",
     "shell.execute_reply.started": "2024-07-15T07:52:27.710175Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.6936470759766442 accuracy 0.524128936090926\n",
      "Val   loss 0.6859463113877509 accuracy 0.5591304347826087\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.6484333027508997 accuracy 0.6150549655300913\n",
      "Val   loss 0.6054862609340085 accuracy 0.6695652173913044\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.5527460214992365 accuracy 0.7147382150177007\n",
      "Val   loss 0.555200474957625 accuracy 0.7078260869565217\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.45380250260322574 accuracy 0.786659213713434\n",
      "Val   loss 0.5881015070610576 accuracy 0.7147826086956522\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.3462102554649824 accuracy 0.8438606297745481\n",
      "Val   loss 0.6905306815687153 accuracy 0.7173913043478262\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.2439784881592329 accuracy 0.8937954164337618\n",
      "Val   loss 0.8390817942304744 accuracy 0.7121739130434783\n",
      "\n",
      "Epoch 00006: reducing learning rate of group 0 to 8.0000e-07.\n",
      "Early stopping\n",
      "Test loss 0.5544326988359293 accuracy 0.7219808861859253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('BERT_tokenizer/tokenizer_config.json',\n",
       " 'BERT_tokenizer/special_tokens_map.json',\n",
       " 'BERT_tokenizer/vocab.txt',\n",
       " 'BERT_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.3\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with dropout\n",
    "class CustomBERTModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(outputs.logits)\n",
    "        return pooled_output\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Increased patience\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    reduce_lr_on_plateau.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('BERT_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f8a180-1564-45c0-ac7b-b987951f630e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:01:24.081667Z",
     "iopub.status.busy": "2024-07-15T08:01:24.080825Z",
     "iopub.status.idle": "2024-07-15T08:11:56.043115Z",
     "shell.execute_reply": "2024-07-15T08:11:56.042225Z",
     "shell.execute_reply.started": "2024-07-15T08:01:24.081613Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.689053545572928 accuracy 0.5252468790758338\n",
      "Val   loss 0.6701158376203643 accuracy 0.5634782608695652\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.6223417959575143 accuracy 0.6467300167691448\n",
      "Val   loss 0.6569851222965453 accuracy 0.611304347826087\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.5444260283949829 accuracy 0.7113843860629775\n",
      "Val   loss 0.5334590031868882 accuracy 0.7373913043478261\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.47534642639082103 accuracy 0.767281535308366\n",
      "Val   loss 0.5303698968556192 accuracy 0.7208695652173913\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.40245883845325026 accuracy 0.795789081423514\n",
      "Val   loss 0.5981410619699292 accuracy 0.7295652173913044\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.3407088693098298 accuracy 0.8386435625116452\n",
      "Val   loss 0.6224692834334241 accuracy 0.7373913043478261\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.28303956967734156 accuracy 0.8600708030557108\n",
      "Val   loss 0.680336385137505 accuracy 0.7321739130434783\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.23294258070555293 accuracy 0.8826159865846842\n",
      "Val   loss 0.7747477448234955 accuracy 0.7347826086956522\n",
      "\n",
      "Epoch 00008: reducing learning rate of group 0 to 2.0000e-07.\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.21078845289247555 accuracy 0.8814980435997763\n",
      "Val   loss 0.8756210617721081 accuracy 0.7295652173913044\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.5414694932599863 accuracy 0.7202432667245873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('BERT_tokenizer/tokenizer_config.json',\n",
       " 'BERT_tokenizer/special_tokens_map.json',\n",
       " 'BERT_tokenizer/vocab.txt',\n",
       " 'BERT_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5  # Lower initial learning rate\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.4  # Increased dropout rate\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with dropout\n",
    "class CustomBERTModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(outputs.logits)\n",
    "        return pooled_output\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Increased patience\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    reduce_lr_on_plateau.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('BERT_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcd0d032-fc15-4208-943f-fc80f66686b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:13:24.411180Z",
     "iopub.status.busy": "2024-07-15T08:13:24.410384Z",
     "iopub.status.idle": "2024-07-15T08:22:44.083754Z",
     "shell.execute_reply": "2024-07-15T08:22:44.082604Z",
     "shell.execute_reply.started": "2024-07-15T08:13:24.411128Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.6867477915116719 accuracy 0.5507732438978945\n",
      "Val   loss 0.6604724104205767 accuracy 0.6121739130434782\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.6269921687032495 accuracy 0.640953978013788\n",
      "Val   loss 0.5720653980970383 accuracy 0.6991304347826087\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.5421194687840485 accuracy 0.718651015464878\n",
      "Val   loss 0.5417799051437113 accuracy 0.7208695652173913\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.4915422878361174 accuracy 0.7514440096888392\n",
      "Val   loss 0.5672738556232717 accuracy 0.7086956521739131\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.41273450709524606 accuracy 0.7963480529159679\n",
      "Val   loss 0.6668571295837561 accuracy 0.6695652173913044\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.36037314536848236 accuracy 0.8203838270914849\n",
      "Val   loss 0.6153321380002631 accuracy 0.7226086956521739\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.29037313673290466 accuracy 0.8475871063909074\n",
      "Val   loss 0.7263538806388775 accuracy 0.7217391304347827\n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.2599685235348131 accuracy 0.8667784609651574\n",
      "Val   loss 0.7874221151901616 accuracy 0.7217391304347827\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.548801744563712 accuracy 0.7106863596872285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('path_to_save_tokenizer/tokenizer_config.json',\n",
       " 'path_to_save_tokenizer/special_tokens_map.json',\n",
       " 'path_to_save_tokenizer/vocab.txt',\n",
       " 'path_to_save_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.4\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "# Initialize DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with dropout\n",
    "class CustomBERTModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(outputs.logits)\n",
    "        return pooled_output\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Increased patience\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    reduce_lr_on_plateau.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('path_to_save_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e1d7c07-315c-4516-931f-f2a82afa47ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:26:40.832244Z",
     "iopub.status.busy": "2024-07-15T08:26:40.831440Z",
     "iopub.status.idle": "2024-07-15T08:35:56.807564Z",
     "shell.execute_reply": "2024-07-15T08:35:56.806641Z",
     "shell.execute_reply.started": "2024-07-15T08:26:40.832193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.6893778051294032 accuracy 0.5274827650456493\n",
      "Val   loss 0.6473154036535157 accuracy 0.631304347826087\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.6304347180717048 accuracy 0.6294019005030743\n",
      "Val   loss 0.5658450085255835 accuracy 0.7243478260869566\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.558461762742982 accuracy 0.6897708216880939\n",
      "Val   loss 0.5339819495048788 accuracy 0.7234782608695652\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.5000564149093061 accuracy 0.722936463573691\n",
      "Val   loss 0.5374440414210161 accuracy 0.7286956521739131\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.4502549637996015 accuracy 0.7607602012297373\n",
      "Val   loss 0.5409121964540746 accuracy 0.7269565217391305\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.3955067682213017 accuracy 0.7883361281907956\n",
      "Val   loss 0.5989082172099087 accuracy 0.7304347826086957\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.3343155712022313 accuracy 0.8116266070430408\n",
      "Val   loss 0.6642975196656253 accuracy 0.7173913043478262\n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.30302165196432423 accuracy 0.8313769331097447\n",
      "Val   loss 0.7001392371538613 accuracy 0.7286956521739131\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.5282167688839965 accuracy 0.7176368375325803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('BERT_tokenizer/tokenizer_config.json',\n",
       " 'BERT_tokenizer/special_tokens_map.json',\n",
       " 'BERT_tokenizer/vocab.txt',\n",
       " 'BERT_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.5  # Increased dropout rate\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "# Initialize DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with dropout\n",
    "class CustomBERTModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "        self.dropout = torch.nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(outputs.logits)\n",
    "        return pooled_output\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Increased patience\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    reduce_lr_on_plateau.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('BERT_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6025508-a496-42f0-a880-c1ce07c7a546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:59:52.525654Z",
     "iopub.status.busy": "2024-07-15T08:59:52.524878Z",
     "iopub.status.idle": "2024-07-15T09:09:11.972663Z",
     "shell.execute_reply": "2024-07-15T09:09:11.971687Z",
     "shell.execute_reply.started": "2024-07-15T08:59:52.525600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.6927994915417263 accuracy 0.5177939258431153\n",
      "Val   loss 0.7044967040419579 accuracy 0.49130434782608695\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.6349575040595872 accuracy 0.6461710452766909\n",
      "Val   loss 0.556188401662641 accuracy 0.7182608695652174\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.518900861342748 accuracy 0.7506987143655673\n",
      "Val   loss 0.5469941529962752 accuracy 0.7139130434782609\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.41871078922191546 accuracy 0.8196385317682131\n",
      "Val   loss 0.5576740495032735 accuracy 0.7478260869565218\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.31392805220647935 accuracy 0.8800074529532327\n",
      "Val   loss 0.6058641725944148 accuracy 0.7356521739130435\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.22812801862268575 accuracy 0.9157816284702813\n",
      "Val   loss 0.7540402385509677 accuracy 0.711304347826087\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.16230433910442071 accuracy 0.9478293273709707\n",
      "Val   loss 0.8414403004571795 accuracy 0.7304347826086957\n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.1208677401134212 accuracy 0.9647847959754052\n",
      "Val   loss 0.8616465125232935 accuracy 0.7286956521739131\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.5418362095952034 accuracy 0.7263249348392702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('path_to_save_tokenizer/tokenizer_config.json',\n",
       " 'path_to_save_tokenizer/special_tokens_map.json',\n",
       " 'path_to_save_tokenizer/vocab.txt',\n",
       " 'path_to_save_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CyclicLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.5\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "# Initialize DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with an additional linear layer\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.output = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "        pooled_output = outputs[1]  # This is the pooled output (CLS token)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.linear(pooled_output)\n",
    "        pooled_output = torch.relu(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.output(pooled_output)\n",
    "        return logits\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Increased patience\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    reduce_lr_on_plateau.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('path_to_save_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ee11d76-4f3b-4e8a-b609-1c9f8ef4659e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T09:13:33.433160Z",
     "iopub.status.busy": "2024-07-15T09:13:33.432525Z",
     "iopub.status.idle": "2024-07-15T09:22:53.428634Z",
     "shell.execute_reply": "2024-07-15T09:22:53.427676Z",
     "shell.execute_reply.started": "2024-07-15T09:13:33.433107Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.693470676385221 accuracy 0.5271101173840134\n",
      "Val   loss 0.7024113949802187 accuracy 0.4921739130434783\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.640000316358748 accuracy 0.6280976336873486\n",
      "Val   loss 0.6106893685128953 accuracy 0.6539130434782608\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.5223235277725118 accuracy 0.7439910564561207\n",
      "Val   loss 0.5289430870778031 accuracy 0.7278260869565217\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.4106111712088542 accuracy 0.8146077883361281\n",
      "Val   loss 0.5652447282854054 accuracy 0.7286956521739131\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.3056984222494066 accuracy 0.8794484814607788\n",
      "Val   loss 0.5981863643974066 accuracy 0.7130434782608696\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.2127051706636502 accuracy 0.9254704676728154\n",
      "Val   loss 0.7665104839122958 accuracy 0.7304347826086957\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.15151308092754334 accuracy 0.9459660890627911\n",
      "Val   loss 0.8358498594413201 accuracy 0.7339130434782609\n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.10759419081954374 accuracy 0.9662753866219489\n",
      "Val   loss 0.9426670798824893 accuracy 0.7182608695652174\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.531105374917388 accuracy 0.734144222415291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('path_to_save_tokenizer/tokenizer_config.json',\n",
       " 'path_to_save_tokenizer/special_tokens_map.json',\n",
       " 'path_to_save_tokenizer/vocab.txt',\n",
       " 'path_to_save_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CyclicLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.5\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with an additional linear layer\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.output = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "        pooled_output = outputs[1]  # This is the pooled output (CLS token)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.linear(pooled_output)\n",
    "        pooled_output = torch.relu(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.output(pooled_output)\n",
    "        return logits\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Increased patience\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    reduce_lr_on_plateau.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('path_to_save_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de3edea8-de24-455d-9951-e9d494073782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T09:29:13.192165Z",
     "iopub.status.busy": "2024-07-15T09:29:13.191296Z",
     "iopub.status.idle": "2024-07-15T09:37:18.980877Z",
     "shell.execute_reply": "2024-07-15T09:37:18.979728Z",
     "shell.execute_reply.started": "2024-07-15T09:29:13.192112Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.680756407213353 accuracy 0.5610210545928824\n",
      "Val   loss 0.620901925696267 accuracy 0.6756521739130436\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.5775648368788617 accuracy 0.6979690702440842\n",
      "Val   loss 0.5551430078016387 accuracy 0.7173913043478262\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.4747558042761825 accuracy 0.7762250791876281\n",
      "Val   loss 0.6024662076185147 accuracy 0.6869565217391305\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.3730006870325832 accuracy 0.8384572386808272\n",
      "Val   loss 0.5805060201221042 accuracy 0.7304347826086957\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.26455820252608864 accuracy 0.8917458542947643\n",
      "Val   loss 0.6588580446938673 accuracy 0.7286956521739131\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.1647245497858551 accuracy 0.941307993292342\n",
      "Val   loss 0.9234709445801046 accuracy 0.7208695652173913\n",
      "\n",
      "Epoch 00006: reducing learning rate of group 0 to 3.4549e-07.\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.0923351839467484 accuracy 0.97074715856158\n",
      "Val   loss 0.9327861248619027 accuracy 0.731304347826087\n",
      "\n",
      "Early stopping\n",
      "Test loss 0.5454047504398558 accuracy 0.7176368375325803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('path_to_save_tokenizer/tokenizer_config.json',\n",
       " 'path_to_save_tokenizer/special_tokens_map.json',\n",
       " 'path_to_save_tokenizer/vocab.txt',\n",
       " 'path_to_save_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/jovyan/sentiment/train_dataset.csv')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the dataset class\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "DROPOUT_PROB = 0.5\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['Tweets'], df['label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "test_texts = test_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TweetDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Initialize the model with an additional linear layer and different activation function\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.output = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "        pooled_output = outputs[1]  # This is the pooled output (CLS token)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.linear(pooled_output)\n",
    "        pooled_output = torch.nn.functional.gelu(pooled_output)  # Use GELU activation\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.output(pooled_output)\n",
    "        return logits\n",
    "\n",
    "model = CustomBERTModel(dropout_prob=DROPOUT_PROB)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Increased patience\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_texts)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    reduce_lr_on_plateau.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_texts)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss} accuracy {test_acc}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('path_to_save_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842e714-964c-441e-b696-8b42c7da5f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
